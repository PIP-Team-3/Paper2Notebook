{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dffd0ce3",
   "metadata": {},
   "source": [
    "# Plan cd5ec794-e628-42a0-90ea-76f1d62bd1a7\n",
    "\n",
    "This notebook was generated automatically from Plan JSON v1.1.\n",
    "It follows the declared dataset, model, and configuration using a\n",
    "deterministic CPU-only workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "\n",
    "EVENTS_PATH = Path(\"events.jsonl\")\n",
    "METRICS_PATH = Path(\"metrics.json\")\n",
    "\n",
    "if EVENTS_PATH.exists():\n",
    "    EVENTS_PATH.unlink()\n",
    "if METRICS_PATH.exists():\n",
    "    METRICS_PATH.unlink()\n",
    "\n",
    "def log_event(event_type: str, payload: dict) -> None:\n",
    "    EVENTS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with EVENTS_PATH.open(\"a\", encoding=\"utf-8\") as stream:\n",
    "        stream.write(json.dumps({\"event\": event_type, **payload}) + \"\\n\")\n",
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if TORCH_AVAILABLE:\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            raise RuntimeError(\"E_GPU_REQUESTED: CUDA devices are not permitted during runs\")\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "log_event(\"stage_update\", {\"stage\": \"seed_check\", \"seed\": SEED})\n",
    "print(\"Notebook generated for Plan cd5ec794-e628-42a0-90ea-76f1d62bd1a7\")\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Seed set to\", SEED)\n",
    "if TORCH_AVAILABLE:\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "else:\n",
    "    print(\"Torch not installed (not required for this plan)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: penaltyshootouts (Uploaded with paper - Supabase Storage)\n",
    "log_event(\"stage_update\", {\"stage\": \"dataset_load\", \"dataset\": \"penaltyshootouts\"})\n",
    "\n",
    "# Download dataset from Supabase signed URL\n",
    "# URL is injected at runtime by the sandbox (24-hour expiration)\n",
    "dataset_url = os.getenv(\"DATASET_URL\")\n",
    "if not dataset_url:\n",
    "    raise ValueError(\"DATASET_URL environment variable not set. Cannot download uploaded dataset.\")\n",
    "\n",
    "log_event(\"info\", {\"message\": f\"Downloading dataset from Supabase: {dataset_url[:50]}...\"})\n",
    "\n",
    "response = requests.get(dataset_url, timeout=300)  # 5 minute timeout for large datasets\n",
    "response.raise_for_status()\n",
    "\n",
    "# Load Excel file from memory\n",
    "df = pd.read_excel(BytesIO(response.content))\n",
    "\n",
    "log_event(\"metric_update\", {\"metric\": \"dataset_rows\", \"value\": len(df)})\n",
    "\n",
    "# Detect target column (common names)\n",
    "target_column = None\n",
    "for col in [\"Win\", \"win\", \"target\", \"label\", \"class\", \"y\", \"Target\", \"Label\"]:\n",
    "    if col in df.columns:\n",
    "        target_column = col\n",
    "        break\n",
    "\n",
    "if target_column is None:\n",
    "    # Fall back to last column\n",
    "    target_column = df.columns[-1]\n",
    "    log_event(\"warning\", {\"message\": f\"No standard target column found. Using last column: {target_column}\"})\n",
    "\n",
    "# Separate features and target\n",
    "y = df[target_column].values\n",
    "X_df = df.drop(columns=[target_column])\n",
    "\n",
    "# Drop high-cardinality string columns (team names, competition names, etc.)\n",
    "# Keep only columns with reasonable cardinality (<50 unique values)\n",
    "for col in X_df.columns:\n",
    "    if X_df[col].dtype == 'object':  # String column\n",
    "        if X_df[col].nunique() > 50:\n",
    "            X_df = X_df.drop(columns=[col])\n",
    "            log_event(\"info\", {\"message\": f\"Dropped high-cardinality column: {col}\"})\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in X_df.columns:\n",
    "    if X_df[col].dtype == 'object':  # String categorical\n",
    "        le = LabelEncoder()\n",
    "        X_df[col] = le.fit_transform(X_df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Convert to numpy array\n",
    "X = X_df.values\n",
    "\n",
    "# Subsample for CPU budget (only if dataset is large)\n",
    "MAX_SAMPLES = int(os.getenv(\"MAX_TRAIN_SAMPLES\", \"5000\"))\n",
    "if len(X) > MAX_SAMPLES:\n",
    "    indices = np.random.RandomState(SEED).choice(len(X), MAX_SAMPLES, replace=False)\n",
    "    X, y = X[indices], y[indices]\n",
    "    log_event(\"info\", {\"message\": f\"Subsampled {len(X)} â†’ {MAX_SAMPLES} rows\"})\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "log_event(\"metric_update\", {\"metric\": \"dataset_samples\", \"value\": len(X)})\n",
    "log_event(\"metric_update\", {\"metric\": \"dataset_features\", \"value\": X.shape[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e985be",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_event(\"stage_update\", {\"stage\": \"model_build\", \"model\": \"simple baseline model\"})\n",
    "model = LogisticRegression(\n",
    "    max_iter=max(100, 5 * 10),\n",
    "    solver=\"lbfgs\",\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "log_event(\"stage_update\", {\"stage\": \"train\"})\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "log_event(\"stage_update\", {\"stage\": \"evaluate\"})\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = float(accuracy_score(y_test, y_pred))\n",
    "precision = float(precision_score(y_test, y_pred, zero_division=0))\n",
    "recall = float(recall_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "}\n",
    "GOAL_VALUE = 0.650000\n",
    "if GOAL_VALUE is not None:\n",
    "    metrics[\"accuracy_gap\"] = accuracy - GOAL_VALUE\n",
    "\n",
    "METRICS_PATH.write_text(json.dumps({\"metrics\": metrics}, indent=2), encoding=\"utf-8\")\n",
    "print(json.dumps({\"metrics\": metrics}, indent=2))\n",
    "log_event(\"metric_update\", {\"metric\": \"accuracy\", \"value\": accuracy})\n",
    "if len(y_pred) > 0:\n",
    "    log_event(\"sample_pred\", {\"label\": int(y_pred[0]), \"stage\": \"evaluate\"})\n",
    "log_event(\"stage_update\", {\"stage\": \"complete\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}