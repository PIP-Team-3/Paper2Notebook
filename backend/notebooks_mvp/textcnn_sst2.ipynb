{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8cc375",
   "metadata": {},
   "source": [
    "# Plan 0d4f0ff4-730f-47dc-a387-7943806fe990\n",
    "\n",
    "This notebook was generated automatically from Plan JSON v1.1.\n",
    "It follows the declared dataset, model, and configuration using a\n",
    "deterministic CPU-only workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e01493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "        import os\n",
    "        import random\n",
    "        import sys\n",
    "        from pathlib import Path\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        try:\n",
    "            import torch\n",
    "            TORCH_AVAILABLE = True\n",
    "        except ImportError:\n",
    "            TORCH_AVAILABLE = False\n",
    "\n",
    "        EVENTS_PATH = Path(\"events.jsonl\")\n",
    "        METRICS_PATH = Path(\"metrics.json\")\n",
    "\n",
    "        if EVENTS_PATH.exists():\n",
    "            EVENTS_PATH.unlink()\n",
    "        if METRICS_PATH.exists():\n",
    "            METRICS_PATH.unlink()\n",
    "\n",
    "        def log_event(event_type: str, payload: dict) -> None:\n",
    "            EVENTS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with EVENTS_PATH.open(\"a\", encoding=\"utf-8\") as stream:\n",
    "                stream.write(json.dumps({\"event\": event_type, **payload}) + \"\n",
    "\")\n",
    "\n",
    "        def seed_everything(seed: int) -> None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            if TORCH_AVAILABLE:\n",
    "                torch.manual_seed(seed)\n",
    "                if torch.cuda.is_available():\n",
    "                    raise RuntimeError(\"E_GPU_REQUESTED: CUDA devices are not permitted during runs\")\n",
    "                torch.backends.cudnn.deterministic = True\n",
    "                torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        SEED = 42\n",
    "        seed_everything(SEED)\n",
    "        log_event(\"stage_update\", {\"stage\": \"seed_check\", \"seed\": SEED})\n",
    "        print(\"Notebook generated for Plan 0d4f0ff4-730f-47dc-a387-7943806fe990\")\n",
    "        print(\"Python version:\", sys.version)\n",
    "        print(\"Seed set to\", SEED)\n",
    "        if TORCH_AVAILABLE:\n",
    "            print(\"Torch version:\", torch.__version__)\n",
    "        else:\n",
    "            print(\"Torch not installed (not required for this plan)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f737b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: sst2 (HuggingFace - cached download)\n",
    "CACHE_DIR = os.getenv(\"DATASET_CACHE_DIR\", \"./data/cache\")\n",
    "OFFLINE_MODE = os.getenv(\"OFFLINE_MODE\", \"false\").lower() == \"true\"\n",
    "\n",
    "log_event(\"stage_update\", {\"stage\": \"dataset_load\", \"dataset\": \"sst2\"})\n",
    "\n",
    "# Load with caching (downloads only if not cached)\n",
    "dataset = load_dataset(\n",
    "    \"glue\", \"sst2\",\n",
    "    cache_dir=CACHE_DIR,\n",
    "    download_mode=\"reuse_dataset_if_exists\",  # Reuse cache if available\n",
    ")\n",
    "\n",
    "# Extract split\n",
    "split_name = \"train\" if \"train\" in dataset else \"train\"\n",
    "train_data = dataset[split_name]\n",
    "\n",
    "# Convert to sklearn-compatible format\n",
    "# Phase 2: Simple bag-of-words (Phase 3 will add real NLP models)\n",
    "\n",
    "# Detect text field (common field names)\n",
    "text_field = None\n",
    "for field in [\"sentence\", \"text\", \"content\", \"review\"]:\n",
    "    if field in train_data.features:\n",
    "        text_field = field\n",
    "        break\n",
    "\n",
    "if text_field is None:\n",
    "    raise ValueError(f\"Could not find text field in dataset. Available fields: {list(train_data.features.keys())}\")\n",
    "\n",
    "# Extract texts and labels\n",
    "texts = [row[text_field] for row in train_data]\n",
    "\n",
    "# Detect label field\n",
    "label_field = \"label\" if \"label\" in train_data.features else list(train_data.features.keys())[1]\n",
    "labels = [row[label_field] for row in train_data]\n",
    "\n",
    "# Vectorize text (bag-of-words for sklearn compatibility)\n",
    "MAX_FEATURES = int(os.getenv(\"MAX_BOW_FEATURES\", \"1000\"))\n",
    "vectorizer = CountVectorizer(max_features=MAX_FEATURES, random_state=SEED)\n",
    "X = vectorizer.fit_transform(texts).toarray()\n",
    "y = np.array(labels)\n",
    "\n",
    "# Subsample for CPU budget\n",
    "MAX_SAMPLES = int(os.getenv(\"MAX_TRAIN_SAMPLES\", \"5000\"))\n",
    "if len(X) > MAX_SAMPLES:\n",
    "    indices = np.random.RandomState(SEED).choice(len(X), MAX_SAMPLES, replace=False)\n",
    "    X, y = X[indices], y[indices]\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "log_event(\"metric_update\", {\"metric\": \"dataset_samples\", \"value\": len(X)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_event(\"stage_update\", {\"stage\": \"model_build\", \"model\": \"Convolutional Neural Network\"})\n",
    "model = LogisticRegression(\n",
    "    max_iter=max(100, 15 * 10),\n",
    "    solver=\"lbfgs\",\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "log_event(\"stage_update\", {\"stage\": \"train\"})\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "log_event(\"stage_update\", {\"stage\": \"evaluate\"})\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = float(accuracy_score(y_test, y_pred))\n",
    "precision = float(precision_score(y_test, y_pred, zero_division=0))\n",
    "recall = float(recall_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "}\n",
    "GOAL_VALUE = 87.200000\n",
    "if GOAL_VALUE is not None:\n",
    "    metrics[\"accuracy_gap\"] = accuracy - GOAL_VALUE\n",
    "\n",
    "METRICS_PATH.write_text(json.dumps({\"metrics\": metrics}, indent=2), encoding=\"utf-8\")\n",
    "print(json.dumps({\"metrics\": metrics}, indent=2))\n",
    "log_event(\"metric_update\", {\"metric\": \"accuracy\", \"value\": accuracy})\n",
    "if len(y_pred) > 0:\n",
    "    log_event(\"sample_pred\", {\"label\": int(y_pred[0]), \"stage\": \"evaluate\"})\n",
    "log_event(\"stage_update\", {\"stage\": \"complete\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}